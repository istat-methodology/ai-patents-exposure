{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8845b1b9",
   "metadata": {},
   "source": [
    "## Semantic Search - PATENTS coding according to ISCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378eb0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U git+https://github.com/istat-methodology/semantic-search.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b893db6",
   "metadata": {},
   "source": [
    "This is needed on Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb608a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0e5926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from semantic_search.data import build_corpus\n",
    "from semantic_search.local import LocalKnowledgeBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e336a7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure specific paths\n",
    "BASE_DIR = \"/home/azureuser/cloudfiles/code/Users/mbruno/ai-patents-exposure/\"\n",
    "\n",
    "# Local environment\n",
    "# BASE_DIR = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54465471",
   "metadata": {},
   "outputs": [],
   "source": [
    "ISCO_PATH = BASE_DIR + \"resources/classification/ISCO-08_structure_and_definitions.xlsx\"\n",
    "PATENTS_SAMPLE_PATH = BASE_DIR + \"sample/patents_sample.xlsx\"\n",
    "OUTPUT_PATH_SEMANTIC = BASE_DIR + \"output/patents_classified_semantic.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898daeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K = 5  # Number of top results to consider for each query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb7f0c",
   "metadata": {},
   "source": [
    "### ISCO & PATENTS pre-processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0acca7",
   "metadata": {},
   "source": [
    "Read and pre-process ISCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b25712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Excel\n",
    "isco_df = pd.read_excel(ISCO_PATH)\n",
    "\n",
    "# Drop columns we won't use (silently ignore if missing)\n",
    "DROP_COLS = [\"Tasks include\", \"Included occupations\", \"Excluded occupations\", \"Notes\"]\n",
    "isco_df.drop(columns=DROP_COLS, inplace=True, errors='ignore')\n",
    "\n",
    "# Keep only Level >= 3 (minor + unit groups) and make a defensive copy\n",
    "sub_major_df = isco_df.loc[isco_df[\"Level\"] >= 3].copy()\n",
    "\n",
    "# Normalize code column to string and trim\n",
    "sub_major_df[\"ISCO 08 Code\"] = sub_major_df[\"ISCO 08 Code\"].astype(str).str.strip()\n",
    "\n",
    "# Derive 3-digit ISCO code:\n",
    "#  - remove all non-digits (handles formats like '221.1', '221-10', etc.)\n",
    "#  - take the first 3 digits (we'll drop rows that don't yield 3 digits)\n",
    "sub_major_df[\"isco3\"] = (\n",
    "    sub_major_df[\"ISCO 08 Code\"]\n",
    "      .str.replace(r\"\\D\", \"\", regex=True)\n",
    "      .str[:3]\n",
    ")\n",
    "\n",
    "# Simple text cleaner: collapse multiple spaces, strip; empty string for NaN\n",
    "def _clean_text(s: object) -> str:\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    s = str(s).replace(\"\\xa0\", \" \")\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# Clean fields needed downstream\n",
    "sub_major_df[\"Title EN\"]   = sub_major_df[\"Title EN\"].map(_clean_text)\n",
    "sub_major_df[\"Definition\"] = sub_major_df[\"Definition\"].map(_clean_text)\n",
    "\n",
    "# Keep only well-formed 3-digit codes (safety)\n",
    "sub_major_df = sub_major_df[sub_major_df[\"isco3\"].str.len() == 3].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ce4296",
   "metadata": {},
   "source": [
    "Build ISCO clean dataset (needed by semantic_search to build the knowledge base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029165ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One title per 3-digit code from Level == 3; drop empty titles\n",
    "titles = (\n",
    "    sub_major_df.loc[sub_major_df[\"Level\"] == 3, [\"isco3\", \"Title EN\"]]\n",
    "      .drop_duplicates(\"isco3\")\n",
    ")\n",
    "titles = titles[titles[\"Title EN\"].str.strip().ne(\"\")].set_index(\"isco3\")\n",
    "\n",
    "# Aggregate all definitions (from Level >= 3) under the same 3-digit code\n",
    "definitions = (\n",
    "    sub_major_df\n",
    "      .groupby(\"isco3\", as_index=True)[\"Definition\"]\n",
    "      .apply(lambda x: _clean_text(\" \".join([t for t in x if t])))\n",
    "      .to_frame()\n",
    ")\n",
    "\n",
    "# Join definitions and titles; INNER keeps only codes with a (non-empty) title\n",
    "isco_clean_df = definitions.join(titles, how=\"inner\").reset_index()\n",
    "\n",
    "# Build the descriptor string used by semantic search\n",
    "#    (markdown ** around the title is intentional for visual emphasis)\n",
    "isco_clean_df[\"descriptor\"] = (\n",
    "    \"**\" + isco_clean_df[\"Title EN\"].str.strip() + \"**. \" +\n",
    "    isco_clean_df[\"Definition\"].str.strip()\n",
    ").str.replace(r\"\\s+\\.\", \".\", regex=True).str.strip()\n",
    "\n",
    "# Tidy column names and order for downstream use\n",
    "isco_clean_df = (\n",
    "    isco_clean_df\n",
    "      .rename(columns={\"isco3\": \"ISCO3\", \"Title EN\": \"title\", \"Definition\": \"definition\"})\n",
    "      .loc[:, [\"ISCO3\", \"title\", \"definition\", \"descriptor\"]]\n",
    "      .sort_values(\"ISCO3\")\n",
    "      .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04829bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "isco_clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9555da2",
   "metadata": {},
   "source": [
    "Read sample patents and generate descriptor (needed by semantic search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5bc497",
   "metadata": {},
   "outputs": [],
   "source": [
    "patents_df = pd.read_excel(PATENTS_SAMPLE_PATH)\n",
    "# Drop unnecessary columns\n",
    "if \"description\" in patents_df.columns:\n",
    "    patents_df = patents_df.drop(\"description\", axis=1)\n",
    "\n",
    "# Descriptor column is used in semantic search\n",
    "patents_df[\"descriptor\"] =  \"**\"+ patents_df[\"title\"].str.strip() + \"**. \" + patents_df[\"abstract\"].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376336bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "patents_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aee565",
   "metadata": {},
   "source": [
    "### Semantic Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f3226b",
   "metadata": {},
   "source": [
    "1. Semantic Search - Build Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a1b038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texts for embedding/search\n",
    "texts = isco_clean_df[\"descriptor\"].tolist()\n",
    "\n",
    "# Sequential numeric IDs (1..N) â€” sorted by ISCO3 already in previous step\n",
    "ids = list(range(len(isco_clean_df)))\n",
    "\n",
    "# Metadata: include both 3-digit ISCO code and title\n",
    "metadata=[{\"code\": c, \"title\": t} for c, t in zip(isco_clean_df[\"ISCO3\"], isco_clean_df[\"title\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2f3325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the corpus\n",
    "corpus = build_corpus(\n",
    "    texts=texts,\n",
    "    ids=ids,\n",
    "    metadata=metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1097dbad",
   "metadata": {},
   "source": [
    "2. Semantic Search - Build Knowledge Base (runs only on GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be074ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = LocalKnowledgeBase(\n",
    "    corpus=corpus,\n",
    "    model_id=\"BAAI/bge-m3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41e170d",
   "metadata": {},
   "source": [
    "3. Extract the list of QUERIES -> The descriptor field in the PATENTS dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054978b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = patents_df[\"descriptor\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe38d3d",
   "metadata": {},
   "source": [
    "4. Now, we can extract the results for each query. We will first extract the top n results, and then extract the unique codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96923953",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = base.search(queries, top_k=TOP_K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033a2868",
   "metadata": {},
   "source": [
    "We need to define a function to parse the results and extract the unique codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ac14be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_results(results):\n",
    "    outs = []\n",
    "    for result in results:\n",
    "\n",
    "        max_scores = {}\n",
    "        for r in result:\n",
    "            code = r.metadata[\"code\"]\n",
    "            score = r.score\n",
    "\n",
    "            if code not in max_scores or score > max_scores[code]:\n",
    "                max_scores[code] = score\n",
    "\n",
    "        outs.append(max_scores)\n",
    "\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bda145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_scores(parsed_results, top_k=TOP_K, code_prefix=\"code_\", score_prefix=\"score_\"):\n",
    "    \"\"\"\n",
    "    Convert a list of dicts (code -> score) into a wide DataFrame with\n",
    "    columns code_1, score_1, ..., code_k, score_k (sorted by descending score).\n",
    "    Missing entries are filled with NaN.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    parsed_results : list[dict]\n",
    "        Each element corresponds to one patent's result: {code: score, ...}\n",
    "    top_k : int | None\n",
    "        Number of top entries to keep. If None, keeps all entries (wide as max length).\n",
    "    code_prefix, score_prefix : str\n",
    "        Column name prefixes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        One row per patent, with columns code_i / score_i.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    max_len = 0\n",
    "\n",
    "    for r in parsed_results:\n",
    "        # be forgiving if r is None or not a dict\n",
    "        items = list(getattr(r, \"items\", lambda: [])())\n",
    "        # sort by score desc\n",
    "        items.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        if top_k is not None:\n",
    "            items = items[:top_k]\n",
    "\n",
    "        row = {}\n",
    "        for i, (code, score) in enumerate(items, start=1):\n",
    "            row[f\"{code_prefix}{i}\"]  = str(code) if code is not None else None\n",
    "            row[f\"{score_prefix}{i}\"] = float(score) if score is not None else None\n",
    "        rows.append(row)\n",
    "        max_len = max(max_len, len(items))\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Ensure consistent column order\n",
    "    k = top_k if top_k is not None else max_len\n",
    "    ordered_cols = [c for i in range(1, k+1) for c in (f\"{code_prefix}{i}\", f\"{score_prefix}{i}\")]\n",
    "    df = df.reindex(columns=ordered_cols)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0011b84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_results = parse_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6d0b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_wide = expand_scores(parsed_results, top_k=TOP_K)\n",
    "\n",
    "# append to your patents dataframe\n",
    "patents_with_scores = pd.concat([patents_df.reset_index(drop=True), scores_wide], axis=1)\n",
    "\n",
    "# optional: round score columns for readability (doesn't affect numeric type)\n",
    "score_cols = [c for c in patents_with_scores.columns if c.startswith(\"score_\")]\n",
    "patents_with_scores[score_cols] = patents_with_scores[score_cols].round(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea4aba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "patents_with_scores.to_csv(OUTPUT_PATH_SEMANTIC, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
