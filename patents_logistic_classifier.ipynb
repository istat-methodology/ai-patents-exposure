{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db5a49d3",
   "metadata": {},
   "source": [
    "## Logistic Classifier -> ISCO 2-digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811541b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b80273f",
   "metadata": {},
   "source": [
    "Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e86e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isco3_to_isco2(code):\n",
    "    \"\"\"Convert a 3-digit ISCO code to 2-digit\"\"\"\n",
    "    if pd.isna(code):\n",
    "        return None\n",
    "    code_str = str(code).strip()\n",
    "    code_str = re.sub(r\"\\D\", \"\", code_str)\n",
    "    return code_str[:2] if len(code_str) >= 2 else None\n",
    "\n",
    "\n",
    "def parse_secondary_codes(val):\n",
    "    \"\"\"Parse stringified list to actual list of secondary codes\"\"\"\n",
    "    try:\n",
    "        codes = ast.literal_eval(val) if isinstance(val, str) else val\n",
    "        return codes if isinstance(codes, list) else []\n",
    "    except Exception:\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afac81b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label dataset path\n",
    "LABELED_DATASET = \"output/patents_classified_500_gpt5_mini.xlsx\"\n",
    "\n",
    "# Minimum number of samples for a label to be considered\n",
    "# This is used to filter out labels with very few samples\n",
    "# to avoid overfitting and ensure meaningful evaluation.\n",
    "MIN_LABEL_SAMPLE = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b571ecb1",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a69e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(LABELED_DATASET)\n",
    "\n",
    "df[\"text\"] = df[\"title\"].fillna(\"\") + \". \" + df[\"abstract\"].fillna(\"\")\n",
    "\n",
    "# Build a list of ISCO-2 labels per patent (primary + secondary)\n",
    "df[\"labels\"] = df.apply(\n",
    "    lambda row: sorted(\n",
    "        set(\n",
    "            [isco3_to_isco2(row[\"primary_code\"])]\n",
    "            + [isco3_to_isco2(c) for c in parse_secondary_codes(row[\"secondary_codes\"])]\n",
    "        )\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Remove rows with no valid labels\n",
    "df = df[df[\"labels\"].apply(lambda x: len([l for l in x if l]) > 0)].reset_index(\n",
    "    drop=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1456949",
   "metadata": {},
   "source": [
    "### Analize labels frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fff50f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten all labels into a single list\n",
    "all_labels = [label for sublist in df[\"labels\"] for label in sublist]\n",
    "label_freq = Counter(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1599bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_keep = {label for label, count in label_freq.items() if count > MIN_LABEL_SAMPLE}\n",
    "labels_to_remove = set(label_freq.keys()) - labels_to_keep\n",
    "\n",
    "print(\"Labels to remove (support < 3):\", sorted(labels_to_remove))\n",
    "print(\"Labels to keep:\", sorted(labels_to_keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf4c73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter dataset: remove rare labels in each row\n",
    "df[\"filtered_labels\"] = df[\"labels\"].apply(lambda labels: [l for l in labels if l in labels_to_keep])\n",
    "\n",
    "# Remove rows with no valid labels after filtering\n",
    "df_filtered = df[df[\"filtered_labels\"].apply(lambda x: len(x) > 0)].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbd7abf",
   "metadata": {},
   "source": [
    "### Logistic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd819058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-label binarization\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(df_filtered[\"filtered_labels\"])\n",
    "class_names = mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f4967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text embedding using sentence-transformers\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Lightweight model\n",
    "X = model.encode(df_filtered[\"text\"].tolist(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfad8a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771b269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-vs-Rest Logistic Regression classifier\n",
    "clf = OneVsRestClassifier(LogisticRegression(max_iter=1000, class_weight=\"balanced\"))\n",
    "clf.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10aad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "Y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89604c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 12: Evaluation\n",
    "micro_f1 = f1_score(Y_test, Y_pred, average=\"micro\")\n",
    "macro_f1 = f1_score(Y_test, Y_pred, average=\"macro\")\n",
    "report = classification_report(Y_test, Y_pred, target_names=class_names)\n",
    "\n",
    "# Print results\n",
    "print(\"âœ… Micro-F1 score:\", micro_f1)\n",
    "print(\"âœ… Macro-F1 score:\", macro_f1)\n",
    "print(\"\\nðŸ“‹ Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9e0e654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(title, abstract, top_n=3):\n",
    "    \"\"\"\n",
    "    Predict the top N ISCO2 labels for a new patent based on probability.\n",
    "    Returns a list of (label, probability) tuples, sorted by confidence.\n",
    "    \"\"\"\n",
    "    # 1. Prepare the input text\n",
    "    text = f\"{title.strip()}. {abstract.strip()}\"\n",
    "\n",
    "    # 2. Compute the embedding\n",
    "    embedding = model.encode([text])  # shape: (1, embedding_dim)\n",
    "\n",
    "    # 3. Predict probabilities for each label\n",
    "    probs = clf.predict_proba(embedding)[0]  # shape: (n_labels,)\n",
    "\n",
    "    # 4. Get top-N label indices (sorted descending)\n",
    "    top_indices = np.argsort(probs)[-top_n:][::-1]\n",
    "    top_labels = mlb.classes_[top_indices]\n",
    "    top_probs = probs[top_indices]\n",
    "\n",
    "    # 5. Return top N (label, probability) pairs\n",
    "    return list(zip(top_labels, top_probs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e738a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”® Top 3 predicted ISCO2 labels:\n",
      "- 25: 0.96\n",
      "- 22: 0.66\n",
      "- 21: 0.39\n"
     ]
    }
   ],
   "source": [
    "title = \"processing data for interpretation\"\n",
    "abstract = \"A system for improving sensor-based decision making provides for the automatic submission of data obtained locally from instrumentation (such as image data) together with the interpretation of that data, which can be the output of some software which has been checked and possibly corrected by a user according to his/her expertise, to a remote database via an internetwork. The submission to the remote database is preferably automatic so that the remote database grows over time. The local site can access the remote database to retrieve information to assist in interpretation of the locally produced data (for example similar images and their corresponding interpretations), or can retrieve updated or improved software or parameters improving the software used for processing the data. The information on the remote database can also be reprocessed by software agents to provide statistical information based on information from a variety of such local sites. The system is particularly useful in improving the interpretation of data which is difficult to interpret such as medical image data (e.g. mammographic or cardiac ultrasound data).\"\n",
    "\n",
    "results = predict_labels(title, abstract)\n",
    "\n",
    "print(\"ðŸ”® Top 3 predicted ISCO2 labels:\")\n",
    "for label, prob in results:\n",
    "    print(f\"- {label}: {prob:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
