{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536091a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b4da4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_log_jsonl(path, abstract, prompt, response, parsed):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    entry = {\n",
    "        \"timestamp\": timestamp,\n",
    "        \"abstract\": abstract,\n",
    "        \"prompt\": prompt,\n",
    "        \"response\": response,\n",
    "        \"parsed\": parsed\n",
    "    }\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84acae01",
   "metadata": {},
   "source": [
    "Load ISCO-08 -> Level 2 (Sub-Major Group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5bfdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_isco_sub_major(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_excel(path, sheet_name='ISCO-08 EN Struct and defin')\n",
    "    sub_major = df[df['Level'] == 2][['ISCO 08 Code', 'Title EN']]\n",
    "    sub_major.columns = ['Code', 'Title']\n",
    "    return sub_major\n",
    "\n",
    "def load_isco_minor(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_excel(path, sheet_name='ISCO-08 EN Struct and defin')\n",
    "    sub_major = df[df['Level'] == 3][['ISCO 08 Code', 'Title EN']]\n",
    "    sub_major.columns = ['Code', 'Title']\n",
    "    return sub_major"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a1fe59",
   "metadata": {},
   "source": [
    "Build OPENAI prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba22611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(abstract: str, isco_sub_major_df: pd.DataFrame) -> str:\n",
    "    entries = \"\\n\".join([f\"{row.Code}: {row.Title}\" for _, row in isco_sub_major_df.iterrows()])\n",
    "    prompt = f\"\"\"You are a labor market expert. Given the following abstract of a patent, your task is to assign the most appropriate ISCO-08 Sub-Major Group code and name (primary match), and list any other relevant secondary matches (optional).\n",
    "\n",
    "Abstract:\n",
    "\\\"\\\"\\\"{abstract}\\\"\\\"\\\"\n",
    "\n",
    "Here is the list of available Sub-Major Groups:\n",
    "{entries}\n",
    "\n",
    "Please respond with:\n",
    "- Primary Sub-Major Group: <code> - <title> with short justification\n",
    "- Secondary Sub-Major Groups (if any): <code> - <title> with short justification\n",
    "\"\"\"\n",
    "    # print(f\"Generated prompt:\\n{prompt}\\n\")\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0695b752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_classification_output(text: str) -> dict:\n",
    "    try:\n",
    "        # --- PRIMARY ---\n",
    "        primary_code = \"\"\n",
    "        primary_comment = \"\"\n",
    "\n",
    "        # Tollerante a spazi, trattini opzionali, newline disordinati\n",
    "        primary_match = re.search(\n",
    "            r\"Primary Sub-Major Group:\\s*(\\d+)\\s*-\\s*([^\\n]+)\\s*\\n\\s*-?\\s*Justification:?\\s*(.*?)(?:\\n\\n|\\Z)\",\n",
    "            text,\n",
    "            re.DOTALL | re.IGNORECASE\n",
    "        )\n",
    "        if primary_match:\n",
    "            primary_code = primary_match.group(1).strip()\n",
    "            primary_comment = primary_match.group(3).strip()\n",
    "\n",
    "        # --- SECONDARY ---\n",
    "        secondary_codes = []\n",
    "        secondary_comment_blocks = []\n",
    "\n",
    "        secondary_section = re.search(\n",
    "            r\"Secondary Sub-Major Groups\\s*(?:\\(if any\\))?:\\s*(.*)\",\n",
    "            text,\n",
    "            re.DOTALL | re.IGNORECASE\n",
    "        )\n",
    "\n",
    "        if secondary_section:\n",
    "            block = secondary_section.group(1)\n",
    "\n",
    "            # Match ogni gruppo secondario (tollerante)\n",
    "            secondary_matches = re.findall(\n",
    "                r\"-?\\s*(\\d+)\\s*-\\s*([^\\n]+?)\\s*\\n\\s*-?\\s*Justification:?\\s*(.*?)(?=\\n\\s*-?\\s*\\d+\\s*-|\\Z)\",\n",
    "                block,\n",
    "                re.DOTALL\n",
    "            )\n",
    "\n",
    "            for code, title, comment in secondary_matches:\n",
    "                secondary_codes.append(code.strip())\n",
    "                comment_clean = f\"{code.strip()} - {title.strip()}: {comment.strip()}\"\n",
    "                secondary_comment_blocks.append(comment_clean)\n",
    "\n",
    "        return {\n",
    "            \"primary_code\": primary_code,\n",
    "            \"primary_code_comment\": primary_comment,\n",
    "            \"secondary_codes\": \", \".join(secondary_codes),\n",
    "            \"secondary_codes_comment\": \" | \".join(secondary_comment_blocks)\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Parsing error: {e}\")\n",
    "        return {\n",
    "            \"primary_code\": \"ERROR\",\n",
    "            \"primary_code_comment\": \"Parsing failed\",\n",
    "            \"secondary_codes\": \"\",\n",
    "            \"secondary_codes_comment\": \"\"\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0f612e",
   "metadata": {},
   "source": [
    "Call OPENAI APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5a5ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_abstract(client, abstract: str, isco_df: pd.DataFrame, log_path=None, model=\"gpt-5\") -> dict:\n",
    "    prompt = generate_prompt(abstract, isco_df)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        content = response.choices[0].message.content\n",
    "        parsed = parse_classification_output(content)\n",
    "\n",
    "        if log_path:\n",
    "            append_log_jsonl(log_path, abstract, prompt, content, parsed)\n",
    "\n",
    "        return parsed\n",
    "    except Exception as e:\n",
    "        print(f\"Errore OpenAI API: {e}\")\n",
    "        return {\n",
    "            \"primary_code\": \"ERROR\",\n",
    "            \"primary_code_comment\": str(e),\n",
    "            \"secondary_codes\": \"\",\n",
    "            \"secondary_codes_comment\": \"\"\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96546b47",
   "metadata": {},
   "source": [
    "Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c764e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "ISCO_PATH = \"resources/classification/ISCO-08_structure_and_definitions.xlsx\"\n",
    "PATENTS_PATH = \"sample/patents_sample.xlsx\"\n",
    "OUTPUT_PATH = \"output/patents_classified.csv\"\n",
    "\n",
    "MODEL = \"gpt-5-mini\"  # Modello da utilizzare, pu√≤ essere gpt-3.5-turbo o gpt-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de24017",
   "metadata": {},
   "source": [
    "Load .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0abb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica la chiave API da file .env\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "log_path = f\"logs/batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125fcfcb",
   "metadata": {},
   "source": [
    "Read data (classification and sample patents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7f07ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isco_df = load_isco_sub_major(ISCO_PATH)\n",
    "isco_df = load_isco_minor(ISCO_PATH)\n",
    "patents_df = pd.read_excel(PATENTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c7262",
   "metadata": {},
   "outputs": [],
   "source": [
    "patents_df = patents_df.drop(\"description\", axis=1).head(10).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8822b88",
   "metadata": {},
   "source": [
    "Prepare the datastructure for storing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a12f361",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "        \"primary_code\": [],\n",
    "        \"primary_code_comment\": [],\n",
    "        \"secondary_codes\": [],\n",
    "        \"secondary_codes_comment\": []\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b36fbd",
   "metadata": {},
   "source": [
    "Invoke OPENAI APIs to classify patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e968202",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in patents_df.iterrows():\n",
    "\tprint(f\"üîç Elaborazione {idx+1}/{len(patents_df)}\")\n",
    "\tclassification = classify_abstract(client, row[\"abstract\"], isco_df, log_path=log_path, model=MODEL)\n",
    "\tfor key in results:\n",
    "\t\tresults[key].append(classification.get(key, \"\"))\n",
    "\tsleep(0.5)  # per evitare rate limit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d180bc",
   "metadata": {},
   "source": [
    "Add results to patents dataframe and save to output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4fe453",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Aggiungi i risultati al dataframe\n",
    "for key in results:\n",
    "\tpatents_df[key] = results[key]\n",
    "\n",
    "patents_df.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f\"‚úÖ File generato: {OUTPUT_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
